# 一、现状和背景
随着MD文档在产品设计中的普及，越来越多的产品经理开始使用 MD 文档替代传统的 RP 来描述产品方案。  
其初衷是提升编写效率与协作便捷性，但在实际落地过程中逐渐暴露出一系列结构性问题。

首先，产品方案文档呈现出“越写越长、越写越散”的趋势。文档内容不断堆叠，逐渐由“流程驱动”退化为“纯文字表述驱动”，大量描述性语言取代了结构化流程与关键决策点，导致文档从“可执行方案”逐步演变为“长篇说明文”。

其次，信息可读性持续下降，研发与测试开始出现严重理解偏差。在实际评审和执行过程中，测试与开发人员频繁反馈“看不懂”“抓不住主流程”“不清楚边界条件”。此时只能依赖与产品经理进行口头或私下沟通进行二次澄清，但这些补充信息无法沉淀为共享知识，导致：

1. **关键决策仅存在于个人认知中**
2. **口头沟通内容无法被复用**
3. **信息在多轮传递中持续衰减与失真**

最终形成**<font style="color:#DF2A3F;">“文档不可执行 → 反复沟通补偿 → 信息再次丢失 → 文档继续膨胀”</font>**的恶性循环。

从根本上看，我们真正需要的并不是一份必须全文通读才能理解的方案，而是一个：

1. **可以“按模块逐步生长”的方案**
2. **具备清晰主干、可逐级展开的结构化方案**
3. **能够被不同角色快速定位并直接执行的工作方案**

然而在现实中，随着字数和复杂度不断上升，完整通读一份产品方案的时间成本呈指数级增长。在高频迭代、并行项目的工作环境下，几乎不存在**“沉浸式完整阅读产品方案”**的客观条件，这使得**文档的实际价值被严重稀释。**

在此背景下，产品方案进一步演变为**<font style="color:#DF2A3F;">“面向 AI 可读，而非面向人可执行”</font>**的形态，程序员转而依赖 AI 理解需求、生成代码，人工对需求的深度理解能力持续下降，排错更多依赖模型而非人本身的判断。最终形成：

**<font style="color:#DF2A3F;">人不再真正理解方案 → 方案不再真正服务人 → 系统整体质量进入持续下行通道。</font>**

**<font style="color:#DF2A3F;">这是一个典型的工具效率提升掩盖认知能力退化、文档形式进化反而削弱工程可控性的系统性问题。</font>**



## 二、理想目标与第一次结构性改造
理想状态下，我期望产品经理在产出产品方案文档之后，**不再依赖额外的串讲**，任何角色在首次阅读时即可**完整理解方案背景、核心流程与边界条件**，实现“**文档即共识**”的效果，而非“**文档只是沟通前的草稿**”。

基于这一目标，在既有现实条件下，我对文档结构进行了第一次工程化改造。核心改造思路并非推倒重来，而是在原有章节体系中**新增统一的「过程说明书」模块**，用于集中呈现完整业务流程。

产品侧的反馈是：  
以往这些内容并非不存在，而是**高度分散在各个章节与零碎描述中**。因此，此次改造的本质并非“新增信息”，而是一次**强制结构化与集中化整理**：

+ 将原本散落于不同章节的流程说明进行统一抽取
+ 融合为一条完整、可追踪、可复用的总流程设计
+ 使用户可以通过单一入口快速定位核心逻辑

在这一阶段，文档的**信息可检索性与路径清晰度确实得到了明显改善**。使用者只需进入该流程模块，进行一次粗粒度扫描，即可对整体方案形成初步认知。

---

## 三、新问题的出现：文本理解的天然效率上限
然而，新的问题随之出现——  
**“阅读理解”在效率上天然不如“口头讲解”。**

即便流程已经被完整、正确、无缺失地写入文档，对于相当一部分使用者而言，**“看懂”依然明显慢于“听懂”**。基于长期观察，我对“看不懂文字”的现象进行了简单抽象，发现具有明显的共性特征：

1. 人类天生对**口语化表达具有更高的注意力黏性与理解容忍度**
2. 对**可反复追问、即时澄清、不确定性可即时消除的沟通方式具有天然偏好**
3. 文本即便内容完全等价，由于缺乏即时反馈机制，理解成本依然更高

从认知机制层面看，人类对“**语言交互式理解**”的依赖几乎是写入基因的：  
即使产品经理只是对文档内容进行**原样复述**，并**没有产出任何新增信息量**，听众的理解速度与确定性依然显著高于纯阅读。

这提出了一个本质性问题：

> **文档的信息是完整的，但人类的“吸收路径”并非为纯文本而优化。**
>

---

## 四、不可绕过的客观现实：产品方案天然需要“被讲解”
进一步推论，我逐渐接受了一个客观事实：  
**产品经理的方案，本质上几乎不可能完全脱离“被讲解”这一环节。**

这一现象并非某个团队的执行问题，而是由以下客观因素共同决定的：

+ 方案本身涉及高度抽象的业务规则与隐性假设
+ 不同角色关注点天然不同（产品、研发、测试看问题的角度不同）
+ 大脑对“被引导理解”的路径依赖强于“自主构建理解”

这一过程类似于制造业中的“模具出炉”：  
**模具成型只是第一步，真正具备可用性，仍然依赖“人工打磨”。**

既然“解释”这一环节不可避免，问题便发生了转移：



**<font style="color:#DF2A3F;">既然人必须要“解释”，那“解释者”能否不再是人？</font>**

## 五、问题重构：是否可以用机器替代“讲解者”？
由此产生了一个新的技术命题：

+ 是否可以用 AI 作为产品经理的“嘴替”
+ 让“讲解”从依赖个人精力，转变为可扩展、可复用、可追溯的系统能力
+ 使“方案解释”从一次性成本，演变为可规模化复用的基础设施

这并不是一个纯粹的“效率工具”问题，而是一个**知识传递形态的系统性重构问题**。



## 六、早期尝试：米多智库的失败教训
在正式进攻当前痛点之前，我们其实做过一个早期的 Agent 尝试，方向略有不同——当时是针对客服产品培训的问题。

项目叫「米多智库」，技术栈很简单：RAG + 大模型。设计看起来非常完美，核心思想和现在要解决的问题类似。但不同的是，当时的目标是回答"所有问题"——任何人问米多的任何事，系统都要能答、 能出方案、能报价、 还要能解决客户问题、能思考历史问题、还要能提升效率、反正有多少公司能力就往里面塞、不但要继承公司历来所有入职员工的智慧、还要能思考智慧的盈余、包括但不限于从以前老旧的迂腐的废弃的陈芝麻烂谷子知识库的馊主意里面产生新的、有效对策。

理想很丰满, 现实太骨感

问题来了：产品经理们无法为未知领域的问题准备好一切方案。系统级问题（整个公司层面）和具体方案层面的问题，难度完全不在一个数量级。再加上 RAG 本身效果拉垮，双重叠加，怎么调都不对。



复盘下来，我们遇到了四个致命问题：

**问题一：提问太泛滥**  
什么问题都有，旧方案永远比新方案多，未知敌人永远比已知的多。用户问不到知识库最新、最擅长的领域去。

**问题二：问题不专业**  
部分提问超脱物理规律，甚至想用一句话解决"如何用1天时间给公司带来100万收入"这种问题。

**问题三：RAG 切分技术太拉垮**  
每个平台有自己的切割方式，属于黑盒切割法。关键词可能被裁成两半。就好比你的书架只能放 A4 纸大小的本子，书稍微大一点就会被裁剪。检索时遇到关键信息缺失、排序错乱、时间优先级混乱等问题。

**问题四：反馈全是负面**  
每一条反馈都在说：你做的系统真的好烂。



我当时就跟老王和洪玉闹, 我说, 你要不给我解决这么多问题, 我就做不成, 我要做的是跨时代的产物, 你只要给我东西, 我就能完成你想要的

这个思维模式就好像有人建议在低迷的酒吧里喊明星来驻唱, 以此来提升销量,  这个建议本身是无比正确, 但是无比的馊



## 七、四味药
吸取教训后，这一次我针对上述四个致命问题，分别开出了四味对症下药的方子。

### 第一味药：面向资料——收窄知识边界
**以前的问题**：知识库试图回答公司所有问题，从产品方案到客户投诉，从技术架构到财务报销，无所不包。结果就是什么都能问，但什么都答不好。RAG 检索出来的内容东一榔头西一棒子，答案永远在"似乎相关"和"完全不对"之间摇摆。

**这一次的策略**：只针对 PRD（产品需求文档）中有明确参考价值的内容。不再大包大揽回答公司的全部问题，只回答"这份方案讲了什么、怎么做、边界在哪"。

**为什么能解决**：知识域收窄后，系统的置信度大幅提升。问一个具体方案的问题，答案就来自这份方案本身，而不是从公司十年积累的各种文档里瞎拼凑。



### 第二味药：面向群体——锁定专业用户
**以前的问题**：面向全员开放，什么人都能来问。客服问怎么安抚客户，销售问怎么报价，运维问服务器怎么配置。问题五花八门，系统疲于应付，最终谁都不满意。

**这一次的策略**：只面向产研团队。提问的人本身就具备专业背景，更有智慧、更专精，问出来的问题和系统擅长回答的问题针尖对麦芒。

**为什么能解决**：产研人员问的是"这个接口怎么设计""这个状态流转的边界条件是什么"，而不是"怎么用一天时间给公司带来一百万收入"。问题专业了，答案自然也专业了。



### 第三味药：面向问题——限定问题分类
**以前的问题**：开放性问题满天飞，用户想用一句话解决战略级难题。系统既要能讲产品功能，又要能出落地方案，还要能预测市场趋势，最后什么都讲不清楚。

**这一次的策略**：只针对具象问题，输出描述性语言和手把手指导。把系统定位成"限定品类的专卖店"，而非"什么都卖的百货商场"。

**为什么能解决**：当用户知道这个系统只能回答"方案里写了什么"，而不是"公司未来怎么发展"，他们的提问自然会收敛到系统能力边界内。期望对齐了，满意度就上来了。



### 第四味药：面向技术——用 Cache 替代 RAG
**以前的问题**：RAG 的切分技术太拉垮。每个平台用自己的黑盒切割法，一份完整的方案被切成碎片，关键词可能被裁成两半。检索时关键信息缺失、排序错乱、时间优先级混乱，拼出来的上下文支离破碎。

**这一次的策略**：直接使用 Cache 技术，一次性将整份 PRD 全部装入上下文，不做任何截断。

**为什么能解决**：不切就不会切错。整份方案完整地放在模型面前，模型看到的就是产品经理写的原貌，不存在信息丢失和拼接失真的问题。代价是 token 消耗更高，但换来的是答案质量的根本性提升。



### 核心思想
这四味药的底层逻辑是同一个：**做减法**。

以前的思路是"我要做一个什么都懂的全能先生"，结果就是什么都懂一点、什么都不精通。这一次的思路是"我只做一个英语专业老师"，只教英语，只带这几个孩子，但教得明白、带得扎实。

专精Agent，才是这一次能成的根本原因。

---

## 八、工程原则补充：服务器优先闭环

为了避免“客户端切换页面/断网/崩溃就导致一次 AI 请求白跑”，系统在工程实现上必须坚持一条原则：

> **从用户发出指令的那一刻开始，闭环在服务器内完成。客户端只负责发送指令与观察结果。**

这意味着：
- 任何 AI 相关的耗时操作都应任务化（返回 `runId/taskId`），由服务端后台执行并落盘。
- 客户端断线不影响任务继续，重进后可通过查询/订阅恢复最终结果。

